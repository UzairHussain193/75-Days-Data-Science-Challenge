{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Available Datasets to Import Directly\n",
    "#### Available on datascience dojo website.\n",
    "\n",
    "## Datasets\n",
    "- Titanic: [titanic.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv)\n",
    "- Iris: [iris.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/iris.csv)\n",
    "- Boston: [boston.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/boston.csv)\n",
    "- Diabetes: [diabetes.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/diabetes.csv)\n",
    "- Wine: [wine.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/wine.csv)\n",
    "- Breast Cancer: [breast-cancer.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/breast-cancer.csv)\n",
    "- Housing: [housing.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/housing.csv)\n",
    "- Heart Disease: [heart-disease.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/heart-disease.csv)\n",
    "- Car Evaluation: [car-evaluation.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/car-evaluation.csv)\n",
    "- Chess: [chess.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/chess.csv)\n",
    "- Adult Census: [adult-census.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/adult-census.csv)\n",
    "- Bank Marketing: [bank-marketing.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/bank-marketing.csv)\n",
    "- Breast Cancer Wisconsin: [breast-cancer-wisconsin.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/breast-cancer-wisconsin.csv)\n",
    "- Credit Card Fraud: [credit-card-fraud.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/credit-card-fraud.csv)\n",
    "- German Credit: [german-credit.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/german-credit.csv)\n",
    "- Haberman's Survival: [haberman-survival.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/haberman-survival.csv)\n",
    "- Mushroom: [mushroom.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/mushroom.csv)\n",
    "- Sonar: [sonar.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/sonar.csv)\n",
    "- Student Performance: [student-performance.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/student-performance.csv)\n",
    "- Wine Quality: [wine-quality.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/wine-quality.csv)\n",
    "- Zoo: [zoo.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/zoo.csv)\n",
    "- Auto MPG: [auto-mpg.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/auto-mpg.csv)\n",
    "- Bike Sharing: [bike-sharing.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/bike-sharing.csv)\n",
    "- Car Evaluation: [car-evaluation.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/car-evaluation.csv)\n",
    "- Computer Hardware: [computer-hardware.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/computer-hardware.csv)\n",
    "- Forest Fires: [forest-fires.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/forest-fires.csv)\n",
    "- Haberman's Survival: [haberman-survival.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/haberman-survival.csv)\n",
    "- Student Performance: [student-performance.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/student-performance.csv)\n",
    "- Wine Quality: [wine-quality.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/wine-quality.csv)\n",
    "- Zoo: [zoo.csv](https://raw.githubusercontent.com/datasciencedojo/datasets/master/zoo.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Titanic dataset to titanic.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL for Titanic dataset\n",
    "titanic_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "\n",
    "# Load dataset\n",
    "titanic_data = pd.read_csv(titanic_url)\n",
    "\n",
    "# Save to file\n",
    "titanic_data.to_csv(\"titanic.csv\", index=False)\n",
    "print(\"Saved Titanic dataset to titanic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets in Seaborn:\n",
      "anagrams\n",
      "anscombe\n",
      "attention\n",
      "brain_networks\n",
      "car_crashes\n",
      "diamonds\n",
      "dots\n",
      "dowjones\n",
      "exercise\n",
      "flights\n",
      "fmri\n",
      "geyser\n",
      "glue\n",
      "healthexp\n",
      "iris\n",
      "mpg\n",
      "penguins\n",
      "planets\n",
      "seaice\n",
      "taxis\n",
      "tips\n",
      "titanic\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# List of available datasets in Seaborn\n",
    "available_datasets = sns.get_dataset_names()\n",
    "\n",
    "print(\"Available datasets in Seaborn:\")\n",
    "for dataset in available_datasets:\n",
    "    print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: anagrams\n",
      "Saved anagrams dataset to anagrams.csv\n",
      "Loading dataset: anscombe\n",
      "Saved anscombe dataset to anscombe.csv\n",
      "Loading dataset: attention\n",
      "Saved attention dataset to attention.csv\n",
      "Loading dataset: brain_networks\n",
      "Saved brain_networks dataset to brain_networks.csv\n",
      "Loading dataset: car_crashes\n",
      "Saved car_crashes dataset to car_crashes.csv\n",
      "Loading dataset: diamonds\n",
      "Saved diamonds dataset to diamonds.csv\n",
      "Loading dataset: dots\n",
      "Saved dots dataset to dots.csv\n",
      "Loading dataset: dowjones\n",
      "Saved dowjones dataset to dowjones.csv\n",
      "Loading dataset: exercise\n",
      "Saved exercise dataset to exercise.csv\n",
      "Loading dataset: flights\n",
      "Saved flights dataset to flights.csv\n",
      "Loading dataset: fmri\n",
      "Saved fmri dataset to fmri.csv\n",
      "Loading dataset: geyser\n",
      "Saved geyser dataset to geyser.csv\n",
      "Loading dataset: glue\n",
      "Saved glue dataset to glue.csv\n",
      "Loading dataset: healthexp\n",
      "Saved healthexp dataset to healthexp.csv\n",
      "Loading dataset: iris\n",
      "Saved iris dataset to iris.csv\n",
      "Loading dataset: mpg\n",
      "Saved mpg dataset to mpg.csv\n",
      "Loading dataset: penguins\n",
      "Saved penguins dataset to penguins.csv\n",
      "Loading dataset: planets\n",
      "Saved planets dataset to planets.csv\n",
      "Loading dataset: seaice\n",
      "Saved seaice dataset to seaice.csv\n",
      "Loading dataset: taxis\n",
      "Saved taxis dataset to taxis.csv\n",
      "Loading dataset: tips\n",
      "Saved tips dataset to tips.csv\n",
      "Loading dataset: titanic\n",
      "Saved titanic dataset to titanic.csv\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# List of available datasets in Seaborn\n",
    "available_datasets = sns.get_dataset_names()\n",
    "\n",
    "# Function to load and save a single dataset\n",
    "def load_and_save_dataset(name):\n",
    "    print(f\"Loading dataset: {name}\")\n",
    "    # Load dataset\n",
    "    dataset = sns.load_dataset(name)\n",
    "    # Save to file\n",
    "    file_name = f\"{name}.csv\"\n",
    "    dataset.to_csv(file_name, index=False)\n",
    "    print(f\"Saved {name} dataset to {file_name}\")\n",
    "\n",
    "# Load and save each dataset one by one\n",
    "for dataset_name in available_datasets:\n",
    "    load_and_save_dataset(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
